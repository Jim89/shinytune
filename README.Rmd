---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# shinytune

<!-- badges: start -->
<!-- badges: end -->

The goal of shinytune is to make it easy to explore `tune` objects, similar to
`shinystan`.

To do this I need to:

* [ ] Figure out exactly what `tune` is producing
* [ ] Think about some sensible summaries/visualisations/explorations that could
be applied to that
* [ ] (Optionally) Compare to `shinystan` for reference (I don't want to anchor
too strongly to it, though)

## Exploring `tune`

Firstly, I need to figure out what  `tune` object actually contains.

Let's create one following the Getting Started guide on
the [tune
website](https://tidymodels.github.io/tune/articles/getting_started.html).

```{r}
library(tidymodels)
library(tune)
```

### Create the tune objects

Let's just create the whole set of outputs for the Getting Started vignette.

Firstly we'll set up the data:

```{r}
library(AmesHousing)

ames <- make_ames()

set.seed(4595)
data_split <- initial_split(ames, strata = "Sale_Price")
ames_train <- training(data_split)
ames_test  <- testing(data_split)
```

Then the baseline recipe

```{r}
ames_rec <- recipe(Sale_Price ~ Longitude + Latitude, data = ames_train) %>% 
  step_log(Sale_Price, base = 10) %>% 
  step_ns(Longitude, deg_free = tune("long df")) %>% 
  step_ns(Latitude,  deg_free = tune("lat df"))

ames_rec
```

Then update the parameters to use a better function with a wider range: 

```{r}
ames_param <- ames_rec %>% 
  parameters() %>% 
  update(
    `long df` = spline_degree(), 
    `lat df` = spline_degree()
  )

ames_param
```

Then we'll set up the (grid) search space of values for these parameters:

```{r}
spline_grid <- grid_max_entropy(ames_param, size = 10)
spline_grid
```

Then our (linear) model:

```{r}
lm_mod <- linear_reg() %>% 
    set_engine("lm")

lm_mod
```

Then we'll set up the cross validation scheme to search over:

```{r}
set.seed(2453)
cv_splits <- vfold_cv(ames_train, v = 10, strata = "Sale_Price")
```

#### `tune_grid()`

Then finally we'll do the tuning using `tune_grid()`:

```{r cache = TRUE}
ames_res <- tune_grid(
    ames_rec,
    model = lm_mod,
    resamples = cv_splits,
    grid = spline_grid
)
ames_res
```

Let's start out by looking at the class of those results:

```{r}
class(ames_res)
```

As detailed in the `?tune_grid` documentation, we have an updated resamples
result, but with some new info an an extra class. But ultimately it's still a
rectangle. Let's check the methods for the new class (the first one) to see what
might be available "for free".

```{r}
methods(class = class(ames_res)[[1]])
```

So the only built-in method for the `_results` is `autoplot()`. So there's not a
huge amount we get out using S3.

What does the `autoplot()` look like?

```{r}
autoplot(ames_res)
```

We've got the performance metrics over our parameter value(s).

Let's look at the extra columns in a bit more detail:

```{r}
ames_res$.metrics[[1]]
```

`.metrics`, contrains the error/summary metrics for each combination of the
parameters in our grid. Per the docs, the model type informs the default choice
of metric, but we can also specify what we're after with the `metrics` parameter
in `tune_grid()`.

The `.notes` column should contain extra warnings/errors that occurred during
execution.

```{r}
map_dfr(ames_res$.notes, I)
```

We didn't have any here.

The docs also show the `collect_metrics()` function for aggregating the error
metrics over the resamples. We can get summary (mean) values per grid
combination (the default):

```{r}
collect_metrics(ames_res)
```

Or not, in which case we get the exact metrics from each fold (maybe useful if
we want to compute our own summaries).

```{r}
collect_metrics(ames_res, FALSE)
```

The documentation then uses these result to plot/calcualte bespoke summaries to
inform modelling decisions, and the use of `tune` or other `tidymodels`
functions/packages seems to end.

In any case, the output seems reasonably simple: `tune_grid()` will return a set
of metrics (that may be customised via the `metrics`) argument for each
combination in the grid.
